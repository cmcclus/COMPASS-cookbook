{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "dried-revolution",
   "metadata": {},
   "source": [
    "## CREATE DATAFRAME OF ALL NEEDED GV DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "endless-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules \n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import netcdf\n",
    "import math as math\n",
    "import pandas as pd\n",
    "from matplotlib import gridspec\n",
    "import datetime as dt \n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import bottleneck as bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "twelve-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime(year, month, day, sec):\n",
    "        \n",
    "    Y = year\n",
    "    M = month\n",
    "    D = day\n",
    "    \n",
    "    hours = sec/3600.\n",
    "    \n",
    "    if (hours>=24)&(hours<48):\n",
    "        D=day+1\n",
    "        hours = (sec/3600.)-24\n",
    "        \n",
    "    if hours>=48:\n",
    "        D=day+2\n",
    "        hours = (sec/3600.)-48   \n",
    "        \n",
    "    if (M==12) & (D>31):\n",
    "        D=D-31\n",
    "        M = 1\n",
    "        Y = year+1\n",
    "        \n",
    "    if (M==1) & (D>31):\n",
    "        D=D-31\n",
    "        M = 2\n",
    "        \n",
    "    if (M==2) & (D>28):\n",
    "        D=D-28\n",
    "        M = 3\n",
    "\n",
    "    h = int(np.floor(hours))\n",
    "    \n",
    "    minutes = (hours-h)*60.\n",
    "    m = int(np.floor(minutes))\n",
    "\n",
    "    seconds = (minutes-m)*60.\n",
    "    s = int(np.floor(seconds))\n",
    "        \n",
    "    datetime_fmt = dt.datetime(Y,M,D,h,m,s)\n",
    "        \n",
    "    return(datetime_fmt)\n",
    "\n",
    "\n",
    "def get_datetime_GV(month, day, time):\n",
    "    datetime = []\n",
    "    for k in range(len(time)):\n",
    "        D = day \n",
    "        M = month\n",
    "        Y = 2018\n",
    "\n",
    "        sec = time[k]\n",
    "\n",
    "        hours = sec/3600.\n",
    "        h = int(np.floor(hours))\n",
    "\n",
    "        minutes = (hours-h)*60.\n",
    "        m = int(np.floor(minutes))\n",
    "\n",
    "        seconds = (minutes-m)*60.\n",
    "        s = int(np.floor(seconds))\n",
    "\n",
    "        if h>=24:\n",
    "            h = h-24\n",
    "            D = D+1\n",
    "            if (M==1) & (D>=31):\n",
    "                M = M+1\n",
    "                D = 1\n",
    "            if (M==2) & (D>=28):\n",
    "                M = M+1\n",
    "                D = 1\n",
    "            if (M==3) & (D>=31):\n",
    "                M = M+1\n",
    "                D = 1\n",
    "\n",
    "        datetime_fmt = dt.datetime(int(Y),int(M),int(D),h,m,s)\n",
    "        datetime.append(datetime_fmt)\n",
    "    return(datetime)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-steal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rapid-review",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cmcclus/anaconda3/lib/python3.7/site-packages/scipy/io/netcdf.py:314: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\n",
      "  ), category=RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# identify filenames for all flights.\n",
    "opth= '/Users/cmcclus/Documents/McCluskey/projects/SOAR/SOC/SOC_obs/' #Christina's Mac\n",
    "fspec='SOCRATESrf'\n",
    "filename = sorted(glob.glob(opth+fspec+'*.nc'))\n",
    "\n",
    "fillvalue = -32767\n",
    "\n",
    "# read first flight of data to set up dataframe \n",
    "k = 0\n",
    "GV_filename = filename[k]\n",
    "nc_GV = netcdf.netcdf_file(GV_filename, 'r')\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# TIME is a pain. \n",
    "# Time = seconds since X\n",
    "GV_seconds = np.array(nc_GV.variables['Time'][:])\n",
    "\n",
    "# FlightDate = date of flight (MM/DD/YYYY)\n",
    "GV_month = int(nc_GV.FlightDate[0:2])\n",
    "GV_day = int(nc_GV.FlightDate[3:5])\n",
    "\n",
    "# convert to datetime format \n",
    "GV_datetime = get_datetime_GV(GV_month, GV_day, GV_seconds)\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Met data\n",
    "# PSXC = Pressure (hPa)\n",
    "GV_P = np.array(nc_GV.variables['PSXC'][:], dtype='f')\n",
    "GV_P[GV_P == fillvalue]=np.nan\n",
    "\n",
    "# LAT = Latitude (deg N)\n",
    "GV_lat = np.array(nc_GV.variables['LAT'][:], dtype='f')\n",
    "GV_lat[GV_lat == fillvalue]=np.nan\n",
    "\n",
    "# LON = Longitude (deg E)\n",
    "GV_lon = np.array(nc_GV.variables['LON'][:], dtype='f')\n",
    "GV_lon[GV_lon == fillvalue]=np.nan\n",
    "\n",
    "# RHUM = Relative Humidity (%)\n",
    "GV_RH = np.array(nc_GV.variables['RHUM'][:], dtype='f')\n",
    "GV_RH[GV_RH == fillvalue]=np.nan\n",
    "\n",
    "# ATX = air temperature (deg C)\n",
    "GV_T = np.array(nc_GV.variables['ATX'][:], dtype='f')\n",
    "GV_T[GV_T == fillvalue]=np.nan\n",
    "\n",
    "# GEOPTH = geopotential height (m)\n",
    "GV_Z = np.array(nc_GV.variables['GEOPTH'][:], dtype='f')\n",
    "GV_Z[GV_Z == fillvalue]=np.nan\n",
    "\n",
    "# CVCWCC = Liquid water content (g/m2) from CDP\n",
    "GV_LWC_CDP = np.array(nc_GV.variables['CVCWCC'][:], dtype='f')\n",
    "GV_LWC_CDP[GV_LWC_CDP == fillvalue]=np.nan\n",
    "\n",
    "# CVINLET = CVI inlet flag, 0=CVI, 1=Total\n",
    "GV_CVINLET = np.array(nc_GV.variables['CVINLET'][:], dtype='f')\n",
    "GV_CVINLET[GV_CVINLET == fillvalue]=np.nan\n",
    "\n",
    "# CVTS = CVI Temperature Sample Line (deg C)\n",
    "GV_CVTS = np.array(nc_GV.variables['CVTS'][:], dtype='f')\n",
    "GV_CVTS[GV_CVTS == fillvalue]=np.nan\n",
    "\n",
    "# PLWCC = Corrected PMS-King Liquid Water Content (g/m3)\n",
    "GV_PLWCC = np.array(nc_GV.variables['PLWCC'][:], dtype='f')\n",
    "GV_PLWCC[GV_PLWCC == fillvalue]=np.nan\n",
    "\n",
    "# PLWC2DCA_RWOI = Fast 2DC Liquid Water Content, All Particles (g/m3)\n",
    "GV_LWC2DC = np.array(nc_GV.variables['PLWC2DCA_RWOI'][:], dtype='f')\n",
    "GV_LWC2DC[GV_LWC2DC == fillvalue]=np.nan\n",
    "\n",
    "# WIC = Vertical Velocity (m/s)\n",
    "GV_w = np.array(nc_GV.variables['WIC'][:], dtype='f')\n",
    "GV_w[GV_w == fillvalue]=np.nan\n",
    "\n",
    "# GEOPTH = geopotential height (m)\n",
    "GV_Z = np.array(nc_GV.variables['GEOPTH'][:], dtype='f')\n",
    "GV_Z[GV_Z == fillvalue]=np.nan\n",
    "\n",
    "# CONCN = CN concentration (/cc)\n",
    "GV_Ncn = np.array(nc_GV.variables['CONCN'][:], dtype='f')\n",
    "GV_Ncn[GV_Ncn == fillvalue]=np.nan\n",
    "\n",
    "# WSC = GPS-Corrected Horizontal Wind Speed (m/s)\n",
    "GV_ws = np.array(nc_GV.variables['WSC'][:], dtype='f')\n",
    "GV_ws[GV_ws == fillvalue]=np.nan\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "data = {'datetime':GV_datetime, \n",
    "        'pressure':GV_P, \n",
    "        'lat':GV_lat, \n",
    "        'lon':GV_lon, \n",
    "        'relhum':GV_RH, \n",
    "        'temp':GV_T, \n",
    "        'cwc_cdp':GV_LWC_CDP, \n",
    "        'w':GV_w, \n",
    "        'Z':GV_Z, \n",
    "        'Ncn':GV_Ncn, \n",
    "        'ws':GV_ws,\n",
    "        'CVINLET':GV_CVINLET,\n",
    "        'CVTS':GV_CVTS,\n",
    "        'PLWCC':GV_PLWCC,\n",
    "        'LWC2DC':GV_LWC2DC}\n",
    "\n",
    "gv_df = pd.DataFrame(data=data)\n",
    "\n",
    "# ------------------------------------------------------------------------- \n",
    "# particle distribution measurements \n",
    "GV_UHSAS_n = nc_GV.variables['CUHSAS_LWII'][:,0,1:] # #/cc (per bin)\n",
    "GV_UHSAS_size = nc_GV.variables['CUHSAS_LWII'].CellSizes # micrometer\n",
    "\n",
    "GV_UHSAS_CVI_n = nc_GV.variables['CUHSAS_CVIU'][:,0,1:] # #/cc\n",
    "GV_UHSAS_CVI_size = nc_GV.variables['CUHSAS_CVIU'].CellSizes # micrometer\n",
    "\n",
    "GV_CDP_n = nc_GV.variables['CCDP_RWIO'][:,0,1:] # #/cc\n",
    "GV_CDP_size = nc_GV.variables['CCDP_RWIO'].CellSizes #micrometer\n",
    "\n",
    "for i in range(len(filename)-1):\n",
    "    k = i+1\n",
    "    \n",
    "    GV_filename = filename[k]\n",
    "    nc_GV = netcdf.netcdf_file(GV_filename, 'r')\n",
    "    \n",
    "    # ----------\n",
    "    # TIME is a pain. \n",
    "    # Time = seconds since X\n",
    "    GV_seconds = np.array(nc_GV.variables['Time'][:])\n",
    "\n",
    "    # FlightDate = date of flight (MM/DD/YYYY)\n",
    "    GV_month = int(nc_GV.FlightDate[0:2])\n",
    "    GV_day = int(nc_GV.FlightDate[3:5])\n",
    "\n",
    "    # convert to datetime format \n",
    "    GV_datetime = get_datetime_GV(GV_month, GV_day, GV_seconds)\n",
    "    # ----------\n",
    "\n",
    "    # PSXC = Pressure (hPa)\n",
    "    GV_P = np.array(nc_GV.variables['PSXC'][:], dtype='f')\n",
    "    GV_P[GV_P == fillvalue]=np.nan\n",
    "\n",
    "    # LAT = Latitude (deg N)\n",
    "    GV_lat = np.array(nc_GV.variables['LAT'][:], dtype='f')\n",
    "    GV_lat[GV_lat == fillvalue]=np.nan\n",
    "\n",
    "    # LON = Longitude (deg E)\n",
    "    GV_lon = np.array(nc_GV.variables['LON'][:], dtype='f')\n",
    "    GV_lon[GV_lon == fillvalue]=np.nan\n",
    "\n",
    "    # RHUM = Relative Humidity (%)\n",
    "    GV_RH = np.array(nc_GV.variables['RHUM'][:], dtype='f')\n",
    "    GV_RH[GV_RH == fillvalue]=np.nan\n",
    "\n",
    "    # ATX = air temperature (deg C)\n",
    "    GV_T = np.array(nc_GV.variables['ATX'][:], dtype='f')\n",
    "    GV_T[GV_T == fillvalue]=np.nan\n",
    "\n",
    "    # GEOPTH = geopotential height (m)\n",
    "    GV_Z = np.array(nc_GV.variables['GEOPTH'][:], dtype='f')\n",
    "    GV_Z[GV_Z == fillvalue]=np.nan\n",
    "    \n",
    "    # CVCWCC = Liquid water content (g/m2) from CDP\n",
    "    GV_LWC_CDP = np.array(nc_GV.variables['CVCWCC'][:], dtype='f')\n",
    "    GV_LWC_CDP[GV_LWC_CDP == fillvalue]=np.nan\n",
    "\n",
    "    # WIC = Vertical Velocity (m/s)\n",
    "    GV_w = np.array(nc_GV.variables['WIC'][:], dtype='f')\n",
    "    GV_w[GV_w == fillvalue]=np.nan\n",
    "\n",
    "    # GEOPTH = geopotential height (m)\n",
    "    GV_Z = np.array(nc_GV.variables['GEOPTH'][:], dtype='f')\n",
    "    GV_Z[GV_Z == fillvalue]=np.nan\n",
    "\n",
    "    # CONCN = CN concentration (/cc)\n",
    "    GV_Ncn = np.array(nc_GV.variables['CONCN'][:], dtype='f')\n",
    "    GV_Ncn[GV_Ncn == fillvalue]=np.nan\n",
    "    \n",
    "    # WSC = GPS-Corrected Horizontal Wind Speed (m/s)\n",
    "    GV_ws = np.array(nc_GV.variables['WSC'][:], dtype='f')\n",
    "    GV_ws[GV_ws == fillvalue]=np.nan\n",
    "    \n",
    "    # CVINLET = CVI inlet flag, 0=CVI, 1=Total\n",
    "    GV_CVINLET = np.array(nc_GV.variables['CVINLET'][:], dtype='f')\n",
    "    GV_CVINLET[GV_CVINLET == fillvalue]=np.nan\n",
    "        \n",
    "    # CVTS = CVI Temperature Sample Line (deg C)\n",
    "    GV_CVTS = np.array(nc_GV.variables['CVTS'][:], dtype='f')\n",
    "    GV_CVTS[GV_CVTS == fillvalue]=np.nan\n",
    "        \n",
    "    # PLWCC = CDP Water/Ice Content (g/m3)\n",
    "    GV_PLWCC = np.array(nc_GV.variables['PLWCC'][:], dtype='f')\n",
    "    GV_PLWCC[GV_PLWCC == fillvalue]=np.nan\n",
    "    \n",
    "    # PLWC2DCA_RWOI = Fast 2DC Liquid Water Content, All Particles (g/m3)\n",
    "    GV_LWC2DC = np.array(nc_GV.variables['PLWC2DCA_RWOI'][:], dtype='f')\n",
    "    GV_LWC2DC[GV_LWC2DC == fillvalue]=np.nan\n",
    "    \n",
    "    data = {'datetime':GV_datetime, \n",
    "            'pressure':GV_P, \n",
    "            'lat':GV_lat, \n",
    "            'lon':GV_lon, \n",
    "            'relhum':GV_RH, \n",
    "            'temp':GV_T,\n",
    "            'cwc_cdp':GV_LWC_CDP, \n",
    "            'w':GV_w, \n",
    "            'Z':GV_Z, \n",
    "            'Ncn':GV_Ncn,\n",
    "            'ws':GV_ws,\n",
    "            'CVINLET':GV_CVINLET,\n",
    "            'CVTS':GV_CVTS,\n",
    "            'PLWCC':GV_PLWCC,\n",
    "            'LWC2DC':GV_LWC2DC}\n",
    "   \n",
    "    dataframe = pd.DataFrame(data=data)\n",
    "    \n",
    "    gv_df=pd.concat([gv_df,dataframe], ignore_index=True)\n",
    "    \n",
    "    # ------------------------------------------------------------------------- \n",
    "    # particle distribution measurements \n",
    "    UHSAS_n = nc_GV.variables['CUHSAS_LWII'][:,0,1:] # #/cc (per bin)\n",
    "    \n",
    "    UHSAS_CVI_n = nc_GV.variables['CUHSAS_CVIU'][:,0,1:] # #/cc\n",
    "\n",
    "    CDP_n = nc_GV.variables['CCDP_RWIO'][:,0,1:] # #/cc\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    GV_UHSAS_n = np.concatenate((GV_UHSAS_n, UHSAS_n), axis =0)\n",
    "    GV_UHSAS_CVI_n = np.concatenate((GV_UHSAS_CVI_n, UHSAS_CVI_n), axis =0)\n",
    "    GV_CDP_n = np.concatenate((GV_CDP_n, CDP_n), axis =0)\n",
    "    \n",
    "GV_UHSAS_n[GV_UHSAS_n==fillvalue]=np.nan\n",
    "GV_UHSAS_CVI_n[GV_UHSAS_CVI_n==fillvalue]=np.nan\n",
    "GV_CDP_n[GV_CDP_n==fillvalue]=np.nan\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "trying-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for size distribution measurements, calculate running mean \n",
    "\n",
    "def rollavg_bottlneck(a,n):\n",
    "    return bn.move_mean(a, window=n,min_count = None)\n",
    "\n",
    "\n",
    "n_bins = (np.shape(GV_UHSAS_n)[1])\n",
    "GV_UHSAS_n_rm = np.zeros(np.shape(GV_UHSAS_n))\n",
    "\n",
    "for i in range(n_bins):\n",
    "    GV_UHSAS_n_rm[:,i] = rollavg_bottlneck(GV_UHSAS_n[:,i], 10)\n",
    "\n",
    "\n",
    "    \n",
    "n_bins = (np.shape(GV_UHSAS_CVI_n)[1])\n",
    "GV_UHSAS_CVI_n_rm = np.zeros(np.shape(GV_UHSAS_CVI_n))\n",
    "\n",
    "for i in range(n_bins):\n",
    "    GV_UHSAS_CVI_n_rm[:,i] = rollavg_bottlneck(GV_UHSAS_CVI_n[:,i], 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "manufactured-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate UHSAS bin midpoints\n",
    "nbins = 99\n",
    "GV_UHSAS_bins = np.zeros([nbins])\n",
    "GV_UHSAS_binwidth = np.zeros([nbins])\n",
    "\n",
    "for i in range(nbins):\n",
    "    GV_UHSAS_bins[i] = (GV_UHSAS_size[i+1]+GV_UHSAS_size[i])/2.\n",
    "    GV_UHSAS_binwidth[i] = (np.log10(GV_UHSAS_size[i+1])-np.log10(GV_UHSAS_size[i]))\n",
    "    \n",
    "GV_UHSAS_dNdlogDp = GV_UHSAS_n[:,:]/GV_UHSAS_binwidth\n",
    "\n",
    "\n",
    "#running mean (rm)\n",
    "GV_UHSAS_dNdlogDp_rm = GV_UHSAS_n_rm[:,:]/GV_UHSAS_binwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "friendly-reserve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wing-mounted UHSAS, lower size (microns) 0.07015499472618103\n",
      "wing-mounted UHSAS, upper size (microns) 0.8081250190734863\n"
     ]
    }
   ],
   "source": [
    "## calculate running mean of UHSAS number concentrations\n",
    "\n",
    "Dp_lower = 5\n",
    "# Dp_upper = -4 # corresponds to 0.9 microns \n",
    "Dp_upper = -8# corresponds to 0.8 microns\n",
    "\n",
    "print('wing-mounted UHSAS, lower size (microns)',GV_UHSAS_bins[Dp_lower])\n",
    "print('wing-mounted UHSAS, upper size (microns)',GV_UHSAS_bins[Dp_upper])\n",
    "\n",
    "GV_nUHSAS_trunc = np.sum(GV_UHSAS_n[:,Dp_lower:Dp_upper], axis =1)\n",
    "gv_df['nUHSAS_trunc'] = GV_nUHSAS_trunc\n",
    "\n",
    "GV_nUHSAS_trunc_rm = np.sum(GV_UHSAS_n_rm[:,Dp_lower:Dp_upper], axis =1)\n",
    "gv_df['nUHSAS_trunc_rm'] = GV_nUHSAS_trunc_rm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "equal-philosophy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'pressure', 'lat', 'lon', 'relhum', 'temp', 'cwc_cdp', 'w',\n",
       "       'Z', 'Ncn', 'ws', 'CVINLET', 'CVTS', 'PLWCC', 'LWC2DC', 'nUHSAS_trunc',\n",
       "       'nUHSAS_trunc_rm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gv_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-orlando",
   "metadata": {},
   "source": [
    "## EXPORT TIMESERIES DATA AS DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "orange-leonard",
   "metadata": {},
   "outputs": [],
   "source": [
    "## export dataframes \n",
    "save_directory = '/Users/cmcclus/Documents/McCluskey/projects/SOAR/SOC/SOC_research_themes/methods/flightlev_CAM6/'\n",
    "gv_df.to_csv(path_or_buf=save_directory+'SOCRATESgv_UHSASqc_M2023.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "indie-finder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify filenames for all flights.\n",
    "opth= '/Users/cmcclus/Documents/McCluskey/projects/SOAR/SOC/SOC_obs/GNI/' #Christina's Mac\n",
    "fspec='GNI_GV_all_SOCRATES'\n",
    "filename = sorted(glob.glob(opth+fspec+'*.nc'))\n",
    "\n",
    "\n",
    "# read first flight of data to set up dataframe \n",
    "GNI_filename = filename[0]\n",
    "GNI_nc = netcdf.netcdf_file(GNI_filename, 'r')\n",
    "\n",
    "\n",
    "data = {'startdatetime':np.array(GNI_nc.variables['starttime_gni'][:]),\n",
    "        'enddatetime':np.array(GNI_nc.variables['endtime_gni'][:]),\n",
    "        'Z':np.array(GNI_nc.variables['Z_gv'][:], dtype='f'),\n",
    "        'lon':np.array(GNI_nc.variables['lon_gv'][:], dtype='f'),\n",
    "        'lat':np.array(GNI_nc.variables['lat_gv'][:], dtype='f'),\n",
    "        'P':np.array(GNI_nc.variables['p_gv'][:], dtype='f'),\n",
    "        'RH':np.array(GNI_nc.variables['rh_gv'][:], dtype='f'), \n",
    "        'T':np.array(GNI_nc.variables['T_gv'][:], dtype='f'),\n",
    "        'Ts':np.array(GNI_nc.variables['Ts_gv'][:], dtype='f'),\n",
    "        'w':np.array(GNI_nc.variables['w_gv'][:], dtype='f'),\n",
    "        'ws':np.array(GNI_nc.variables['ws_gv'][:], dtype='f'),\n",
    "        'Tdiff':np.array(GNI_nc.variables['Tdiff_calc'][:], dtype='f'),\n",
    "        'Ncn':np.array(GNI_nc.variables['Ncn_gv'][:], dtype='f'),\n",
    "        'GF':np.array(GNI_nc.variables['GF_calc'][:], dtype='f'),\n",
    "        'n1p4':np.array(GNI_nc.variables['n1p4_gni'][:], dtype='f'),\n",
    "        'Msalt':np.array(GNI_nc.variables['Msalt_gni'][:], dtype='f'), \n",
    "        'CVINLET':np.array(GNI_nc.variables['CVINLET_gv'][:], dtype='f'), \n",
    "        'cwc_cdp':np.array(GNI_nc.variables['cwc_cdp_gv'][:], dtype='f')}\n",
    "        \n",
    "df_GNI = pd.DataFrame(data=data)\n",
    "\n",
    "# GNI size distributions \n",
    "GNI_bins = np.array(GNI_nc.variables['GNIbins'][:], dtype='f')\n",
    "GNI_dNdlogDp = np.array(GNI_nc.variables['sd_gni'][:], dtype='f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "understood-unknown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['startdatetime', 'enddatetime', 'Z', 'lon', 'lat', 'P', 'RH', 'T', 'Ts',\n",
       "       'w', 'ws', 'Tdiff', 'Ncn', 'GF', 'n1p4', 'Msalt', 'CVINLET', 'cwc_cdp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GNI.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-scene",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-tampa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-upgrade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
